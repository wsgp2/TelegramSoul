#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ChatGPT Telegram Chat Analyzer

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç OpenAI API (gpt-4o-mini –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞, gpt-4o –¥–ª—è –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏) –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ Telegram —á–∞—Ç–æ–≤,
–≤—ã—è–≤–ª–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ–º, —Ç—Ä–µ–Ω–¥–æ–≤ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π.

–û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
–∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç —Å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏.
"""

import os
import json
import logging
import asyncio
import time
from datetime import datetime
import pandas as pd
import numpy as np
import httpx
# –ò–º–ø–æ—Ä—Ç—ã –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —É–±—Ä–∞–Ω—ã –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è
from tqdm import tqdm
from typing import List, Dict, Any, Optional, Tuple
from collections import Counter, defaultdict
import difflib
import re

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(os.path.join('logs', f'chatgpt_analysis_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'))
    ]
)

logger = logging.getLogger(__name__)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π –∫ –¥–∞–Ω–Ω—ã–º
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MESSAGES_DIR = os.path.join(BASE_DIR, 'data', 'messages')
OUTPUT_DIR = os.path.join(BASE_DIR, 'data', 'reports')
VISUALIZATION_DIR = os.path.join(OUTPUT_DIR, 'visualizations')
LOGS_DIR = os.path.join(BASE_DIR, 'logs')

# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
for directory in [MESSAGES_DIR, OUTPUT_DIR, VISUALIZATION_DIR, LOGS_DIR]:
    os.makedirs(directory, exist_ok=True)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è OpenAI API
OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY', '')
MAX_TOKENS = 32000  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è gpt-4o-mini


class ChatGPTAnalyzer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ Telegram-—á–∞—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ChatGPT (gpt-4)
    """
    
    def __init__(self, api_key=None, model="gpt-4o-mini", api_keys=None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        
        Args:
            api_key (str): API –∫–ª—é—á OpenAI. –ï—Å–ª–∏ None, –ø—ã—Ç–∞–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å OPENAI_API_KEY –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è
            model (str): –ú–æ–¥–µ–ª—å OpenAI –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            api_keys (list): –°–ø–∏—Å–æ–∫ API –∫–ª—é—á–µ–π –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö API –∫–ª—é—á–µ–π
        if api_keys and isinstance(api_keys, list):
            self.api_keys = api_keys
            self.api_key = api_keys[0]  # –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª—é—á
        else:
            self.api_key = api_key or OPENAI_API_KEY
            self.api_keys = [self.api_key] if self.api_key else []
        
        if not self.api_keys:
            raise ValueError("API –∫–ª—é—á OpenAI –Ω–µ —É–∫–∞–∑–∞–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY –∏–ª–∏ –ø–µ—Ä–µ–¥–∞–π—Ç–µ –∫–ª—é—á –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞")
        
        self.model = model
        self.messages_dir = MESSAGES_DIR
        self.output_dir = OUTPUT_DIR
        self.visualization_dir = VISUALIZATION_DIR
        self.client = httpx.AsyncClient(timeout=60.0)
        
        logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω ChatGPT-–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å –º–æ–¥–µ–ª—å—é {model}")
        logger.info(f"üöÄ –î–æ—Å—Ç—É–ø–Ω–æ {len(self.api_keys)} API –∫–ª—é—á–µ–π –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
    async def load_messages_from_optimized_format(self, directory=None) -> List[Dict]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
        
        Args:
            directory (str, optional): –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Ñ–∞–π–ª–∞–º–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
            
        Returns:
            List[Dict]: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        """
        directory = directory or self.messages_dir
        all_messages = []
        
        try:
            # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª —Å —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
            files = [f for f in os.listdir(directory) if f.startswith('all_messages_') and f.endswith('.json')]
            if not files:
                logger.error("–§–∞–π–ª—ã —Å —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–±–æ—Ä—â–∏–∫.")
                return []
            
            # –ë–µ—Ä–µ–º —Å–∞–º—ã–π –Ω–æ–≤—ã–π —Ñ–∞–π–ª
            latest_file = sorted(files)[-1]
            file_path = os.path.join(directory, latest_file)
            
            logger.info(f"–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑: {latest_file}")
            
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –¥–≤–∞ —Ñ–æ—Ä–º–∞—Ç–∞: {'messages': [...]} –∏ –ø—Ä–æ—Å—Ç–æ [...]
            if isinstance(data, dict) and 'messages' in data:
                messages = data.get('messages', [])
                metadata = data.get('metadata', {})
                logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π (—Ñ–æ—Ä–º–∞—Ç –æ–±—ä–µ–∫—Ç)")
                logger.info(f"üìä –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {metadata.get('total_chats', 0)} —á–∞—Ç–æ–≤, —Å–æ–±—Ä–∞–Ω–æ {metadata.get('collection_date', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
                return messages
            elif isinstance(data, list):
                logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} —Å–æ–æ–±—â–µ–Ω–∏–π (—Ñ–æ—Ä–º–∞—Ç –º–∞—Å—Å–∏–≤)")
                return data
            else:
                logger.error("‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö")
                return []
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            # Fallback –Ω–∞ —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç
            return await self.load_messages_from_dir_legacy(directory)
    
    async def load_messages_from_dir_legacy(self, directory=None) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤ —Å—Ç–∞—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–µ (fallback)"""
        directory = directory or self.messages_dir
        all_messages = []
        user_ids = []
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (–ø–∞–ø–æ–∫) –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏  
        try:
            user_ids = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]
        except FileNotFoundError:
            logger.error(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {directory} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return []
            
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(user_ids)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {directory}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        for user_id in tqdm(user_ids, desc="–ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö —á–∞—Ç–æ–≤"):
            messages_file = os.path.join(directory, user_id, "messages.json")
            try:
                with open(messages_file, 'r', encoding='utf-8') as f:
                    user_messages = json.load(f)
                    all_messages.extend(user_messages)
            except FileNotFoundError:
                logger.warning(f"–§–∞–π–ª —Å–æ–æ–±—â–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
            except json.JSONDecodeError:
                logger.warning(f"–ù–µ–≤–µ—Ä–Ω—ã–π JSON —Ñ–æ—Ä–º–∞—Ç –≤ —Ñ–∞–π–ª–µ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
        
        logger.info(f"–í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(all_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç {len(user_ids)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
        return all_messages
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥
    async def load_messages_from_dir(self, directory=None) -> List[Dict]:
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –∑–∞–≥—Ä—É–∑–∫–∏ (–ø—Ä–æ–±—É–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, –∑–∞—Ç–µ–º legacy)"""
        return await self.load_messages_from_optimized_format(directory)
    
    def prepare_messages_for_analysis(self, messages: List[Dict], sample_size=None) -> List[str]:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞, –≤—ã–±–∏—Ä–∞—è —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ —É–¥–∞–ª—è—è —Å–ª—É–∂–µ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        
        Args:
            messages (List[Dict]): –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            sample_size (int, optional): –†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏. –ï—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            
        Returns:
            List[str]: –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        """
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        text_messages = []
        for msg in messages:
            if 'content' in msg and isinstance(msg['content'], str) and len(msg['content'].strip()) > 10:
                # –£–¥–∞–ª—è–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –∫–æ–º–∞–Ω–¥—ã –±–æ—Ç–∞–º
                content = msg['content']
                if not content.startswith('/') and not content.startswith('@'):
                    text_messages.append(content)
            elif 'text' in msg and isinstance(msg['text'], str) and len(msg['text'].strip()) > 10:
                # –£–¥–∞–ª—è–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –∫–æ–º–∞–Ω–¥—ã –±–æ—Ç–∞–º
                text = msg['text']
                if not text.startswith('/') and not text.startswith('@'):
                    text_messages.append(text)
            elif 'message' in msg and isinstance(msg['message'], str) and len(msg['message'].strip()) > 2:  
                # –£–¥–∞–ª—è–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –∫–æ–º–∞–Ω–¥—ã –±–æ—Ç–∞–º
                message = msg['message']
                if not message.startswith('/') and not message.startswith('@'):
                    text_messages.append(message)
        
        # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω sample_size, –≤—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—É—é –≤—ã–±–æ—Ä–∫—É
        if sample_size and len(text_messages) > sample_size:
            np.random.seed(42)  # –î–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
            indices = np.random.choice(len(text_messages), sample_size, replace=False)
            text_messages = [text_messages[i] for i in indices]
        
        logger.info(f"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(text_messages)} —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return text_messages
    
    async def call_openai_api(self, messages, temperature=0.3):
        """
        –í—ã–∑—ã–≤–∞–µ—Ç OpenAI API —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π API –∫–ª—é—á)
        
        Args:
            messages (List[Dict]): –°–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è API –≤ —Ñ–æ—Ä–º–∞—Ç–µ [{"role": "...", "content": "..."}]
            temperature (float): –ü–∞—Ä–∞–º–µ—Ç—Ä temperature –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            
        Returns:
            Dict: –û—Ç–≤–µ—Ç –æ—Ç API
        """
        return await self.call_openai_api_with_key(messages, self.api_key, temperature)
    
    async def call_openai_api_with_key(self, messages, api_key, temperature=0.3):
        """
        –í—ã–∑—ã–≤–∞–µ—Ç OpenAI API —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º API –∫–ª—é—á–æ–º
        
        Args:
            messages (List[Dict]): –°–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è API –≤ —Ñ–æ—Ä–º–∞—Ç–µ [{"role": "...", "content": "..."}]
            api_key (str): –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π API –∫–ª—é—á –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            temperature (float): –ü–∞—Ä–∞–º–µ—Ç—Ä temperature –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            
        Returns:
            Dict: –û—Ç–≤–µ—Ç –æ—Ç API
        """
        url = "https://api.openai.com/v1/chat/completions"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        data = {
            "model": self.model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": 4000
        }
        
        try:
            response = await self.client.post(url, headers=headers, json=data)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ OpenAI API: {e}")
            raise
            
    async def analyze_topics(self, text_messages: List[str], max_tokens_per_chunk: int = 8000, checkpoint_base: str = None):
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–º—ã –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ChatGPT —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π checkpoint
        
        Args:
            text_messages (List[str]): –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            max_tokens_per_chunk (int): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ–¥–Ω–æ–º –∑–∞–ø—Ä–æ—Å–µ –∫ API
            checkpoint_base (str): –ë–∞–∑–æ–≤–æ–µ –∏–º—è –¥–ª—è checkpoint —Ñ–∞–π–ª–æ–≤
            
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON
        """
        logger.info("–ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Ç–µ–º –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö...")
        
        # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –º–∞–ª–æ, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ —Å—Ä–∞–∑—É
        if len('\n'.join(text_messages)) < 10000:  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞
            messages_text = '\n'.join(text_messages)
            prompt = TOPIC_ANALYSIS_PROMPT.format(messages=messages_text)
            
            messages_for_api = [
                {"role": "system", "content": "–í—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–º—É –∞–Ω–∞–ª–∏–∑—É –∏ –≤—ã—è–≤–ª–µ–Ω–∏—é —Ç—Ä–µ–Ω–¥–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö."},
                {"role": "user", "content": prompt}
            ]
            
            try:
                response = await self.call_openai_api(messages_for_api, temperature=0.2)
                content = response['choices'][0]['message']['content']
                # –ë–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ JSON
                return self.extract_json_from_text(content)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ç–µ–º: {e}")
                return {"topics": []}
        
        # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –º–Ω–æ–≥–æ, —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏ –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —á–∞—Å—Ç—å
        chunk_size = len(text_messages) // ((len('\n'.join(text_messages)) // max_tokens_per_chunk) + 1)
        chunk_messages = ['\n'.join(text_messages[i:i + chunk_size]) for i in range(0, len(text_messages), chunk_size)]
        
        logger.info(f"–°–æ–æ–±—â–µ–Ω–∏—è —Ä–∞–∑–¥–µ–ª–µ–Ω—ã –Ω–∞ {len(chunk_messages)} —á–∞—Å—Ç–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        # üîÑ –ü–†–û–í–ï–†–Ø–ï–ú CHECKPOINT
        all_topics = []
        start_chunk = 0
        processed_results = []
        
        if checkpoint_base:
            checkpoint_data = self.load_checkpoint(checkpoint_base)
            if checkpoint_data and checkpoint_data.get('total_chunks') == len(chunk_messages):
                processed_results = checkpoint_data.get('chunk_results', [])
                start_chunk = checkpoint_data.get('last_processed_chunk', 0) + 1
                logger.info(f"üîÑ –í–û–°–°–¢–ê–ù–ê–í–õ–ò–í–ê–ï–ú –∞–Ω–∞–ª–∏–∑ —Å —á–∞—Å—Ç–∏ {start_chunk + 1} –∏–∑ {len(chunk_messages)}")
                
                # –î–æ–±–∞–≤–ª—è–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ç–µ–º—ã
                for result in processed_results:
                    if isinstance(result, list):
                        all_topics.extend(result)
                        
            elif checkpoint_data:
                logger.warning("‚ö†Ô∏è Checkpoint –Ω–∞–π–¥–µ–Ω, –Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å—Ç–µ–π –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç. –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–Ω–æ–≤–æ.")
                self.cleanup_checkpoint(checkpoint_base)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —á–∞—Å—Ç–∏
        remaining_chunks = chunk_messages[start_chunk:]
        if not remaining_chunks:
            logger.info("‚úÖ –í—Å–µ —á–∞—Å—Ç–∏ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã! –ó–∞–≤–µ—Ä—à–∞–µ–º –∞–Ω–∞–ª–∏–∑...")
            aggregated_topics = self._aggregate_similar_topics(all_topics)
            if checkpoint_base:
                self.cleanup_checkpoint(checkpoint_base)
            return {"topics": aggregated_topics}
        
        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–≥–æ chunk'–∞
        async def process_chunk(chunk_text, chunk_index, api_key):
            real_index = start_chunk + chunk_index
            logger.info(f"üîÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —á–∞—Å—Ç—å {real_index+1} –∏–∑ {len(chunk_messages)} (API –∫–ª—é—á #{self.api_keys.index(api_key)+1})")
            
            messages = [
                {"role": "system", "content": "–í—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–º—É –∞–Ω–∞–ª–∏–∑—É –∏ –≤—ã—è–≤–ª–µ–Ω–∏—é —Ç—Ä–µ–Ω–¥–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö."},
                {"role": "user", "content": TOPIC_ANALYSIS_PROMPT.format(messages=chunk_text)}
            ]
            
            try:
                response = await self.call_openai_api_with_key(messages, api_key, temperature=0.2)
                content = response['choices'][0]['message']['content']
                
                # –ë–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ JSON
                chunk_topics = self.extract_json_from_text(content)
                topics_found = chunk_topics.get("topics", [])
                logger.info(f"‚úÖ –ß–∞—Å—Ç—å {real_index+1} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞, –Ω–∞–π–¥–µ–Ω–æ {len(topics_found)} —Ç–µ–º")
                return topics_found
                    
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —á–∞—Å—Ç–∏ {real_index+1}: {e}")
                return []
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        tasks = []
        for i, chunk in enumerate(remaining_chunks):
            # –í—ã–±–∏—Ä–∞–µ–º API –∫–ª—é—á –ø–æ –∫—Ä—É–≥—É
            api_key = self.api_keys[i % len(self.api_keys)]
            task = process_chunk(chunk, i, api_key)
            tasks.append(task)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –≥—Ä—É–ø–ø–∞–º–∏ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É API –∫–ª—é—á–µ–π
        batch_size = len(self.api_keys)
        for i in range(0, len(tasks), batch_size):
            batch = tasks[i:i+batch_size]
            batch_start_idx = start_chunk + i
            logger.info(f"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –≥—Ä—É–ø–ø—ã {i//batch_size+1}, –∑–∞–¥–∞—á: {len(batch)} (—á–∞—Å—Ç–∏ {batch_start_idx+1}-{batch_start_idx+len(batch)})")
            
            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –∑–∞–¥–∞—á –≤ –≥—Ä—É–ø–ø–µ
            results = await asyncio.gather(*batch, return_exceptions=True)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for j, result in enumerate(results):
                current_chunk_idx = batch_start_idx + j
                
                if isinstance(result, list):
                    all_topics.extend(result)
                    processed_results.append(result)
                    
                    # üíæ –°–û–•–†–ê–ù–Ø–ï–ú CHECKPOINT –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã
                    if checkpoint_base:
                        self.save_checkpoint(processed_results, current_chunk_idx, len(chunk_messages), checkpoint_base)
                        
                elif isinstance(result, Exception):
                    logger.error(f"–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –≤ –∑–∞–¥–∞—á–µ —á–∞—Å—Ç–∏ {current_chunk_idx+1}: {result}")
                    processed_results.append([])  # –ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Ä—è–¥–∫–∞
                
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º —Å—Ö–æ–∂–∏–µ —Ç–µ–º—ã
        aggregated_topics = self._aggregate_similar_topics(all_topics)
        
        # üóëÔ∏è –£–¥–∞–ª—è–µ–º checkpoint –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        if checkpoint_base:
            self.cleanup_checkpoint(checkpoint_base)
        
        logger.info(f"–ê–Ω–∞–ª–∏–∑ —Ç–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω. –í—ã—è–≤–ª–µ–Ω–æ {len(aggregated_topics)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–µ–º")
        return {"topics": aggregated_topics}
    
    def extract_json_from_text(self, text):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç JSON –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π"""
        import re  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º re –≤–Ω—É—Ç—Ä–∏ –º–µ—Ç–æ–¥–∞
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ —Ñ–∞–π–ª –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        os.makedirs(LOGS_DIR, exist_ok=True)
        log_file_path = os.path.join(LOGS_DIR, f"json_extraction_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")
        
        with open(log_file_path, 'w', encoding='utf-8') as f:
            f.write(f"--- –¢–µ–∫—Å—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è JSON ---\n{text}\n--- –ö–æ–Ω–µ—Ü —Ç–µ–∫—Å—Ç–∞ ---")
        
        logger.info(f"–¢–µ–∫—Å—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è JSON —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {log_file_path}")
        logger.info(f"–ü–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è JSON:\n{text[:500]}")
        logger.info(f"–ü–æ—Å–ª–µ–¥–Ω–∏–µ 500 —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è JSON:\n{text[-500:] if len(text) > 500 else text}")
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 0: –£–¥–∞–ª–µ–Ω–∏–µ –º–∞—Ä–∫–¥–∞—É–Ω –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –æ–±–µ—Ä–Ω—É—Ç –≤ –º–∞—Ä–∫–¥–∞—É–Ω –±–ª–æ–∫ –∫–æ–¥–∞ ```json ... ```
            code_block_pattern = r'```(?:json)?(.*?)```'
            code_blocks = re.findall(code_block_pattern, text, re.DOTALL)
            
            if code_blocks:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π –±–ª–æ–∫ –∫–æ–¥–∞
                json_text = code_blocks[0].strip()
                logger.info(f"–ù–∞–π–¥–µ–Ω JSON –≤ –º–∞—Ä–∫–¥–∞—É–Ω –±–ª–æ–∫–µ –∫–æ–¥–∞, –¥–ª–∏–Ω–∞: {len(json_text)}")
                try:
                    return json.loads(json_text)
                except json.JSONDecodeError as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –∏–∑ –º–∞—Ä–∫–¥–∞—É–Ω –±–ª–æ–∫–∞: {e}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –º–∞—Ä–∫–¥–∞—É–Ω –±–ª–æ–∫–∞: {e}")
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –ü—Ä—è–º–æ–π –ø–∞—Ä—Å–∏–Ω–≥ JSON
        try:
            return json.loads(text)
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}, –ø–æ–∑–∏—Ü–∏—è: {e.pos}, —Å—Ç—Ä–æ–∫–∞: {text[max(0, e.pos-50):e.pos+50] if e.pos < len(text) else '–∫–æ–Ω–µ—Ü —Ç–µ–∫—Å—Ç–∞'}")
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ü–æ–∏—Å–∫ —Ñ–∏–≥—É—Ä–Ω—ã—Ö —Å–∫–æ–±–æ–∫ —Å —É—á–µ—Ç–æ–º –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏
        try:
            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–µ –∏ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–µ —Å–∫–æ–±–∫–∏
            open_braces = [m.start() for m in re.finditer('{', text)]
            close_braces = [m.start() for m in re.finditer('}', text)]
            
            if open_braces and close_braces:
                # –ù–∞–π–¥–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –ø–∞—Ä—É —Å–∫–æ–±–æ–∫, —É—á–∏—Ç—ã–≤–∞—è –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å
                start_index = open_braces[0]  # –ü–µ—Ä–≤–∞—è –æ—Ç–∫—Ä—ã–≤–∞—é—â–∞—è —Å–∫–æ–±–∫–∞
                
                # –°—á–∏—Ç–∞–µ–º –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å —Å–∫–æ–±–æ–∫
                depth = 0
                for i in range(len(text)):
                    if i in open_braces:
                        depth += 1
                    elif i in close_braces:
                        depth -= 1
                        if depth == 0 and i > start_index:
                            # –ù–∞—à–ª–∏ –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ —É—Ä–æ–≤–Ω—è
                            end_index = i
                            json_str = text[start_index:end_index+1]
                            logger.info(f"–ù–∞–π–¥–µ–Ω–∞ JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å —É—á–µ—Ç–æ–º –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏: {start_index} - {end_index}")
                            return json.loads(json_str)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Å–∫–æ–±–æ–∫ —Å —É—á–µ—Ç–æ–º –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏: {e}")
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: –ü–æ–∏—Å–∫ –ø–µ—Ä–≤–æ–π –∏ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ñ–∏–≥—É—Ä–Ω–æ–π —Å–∫–æ–±–∫–∏
        try:
            # –ù–∞—Ö–æ–¥–∏–º –ø–µ—Ä–≤—É—é –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é —Ñ–∏–≥—É—Ä–Ω—É—é —Å–∫–æ–±–∫—É
            start_index = text.find('{')
            end_index = text.rfind('}')
            
            if start_index >= 0 and end_index > start_index:
                json_str = text[start_index:end_index+1]
                logger.info(f"–ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å JSON –º–µ—Ç–æ–¥–æ–º —Å–∫–æ–±–æ–∫: –Ω–∞—á–∞–ª–æ {start_index}, –∫–æ–Ω–µ—Ü {end_index}")
                logger.info(f"–ò–∑–≤–ª–µ–∫–∞–µ–º—ã–π JSON: {json_str[:100]}...{json_str[-100:] if len(json_str) > 200 else json_str}")
                return json.loads(json_str)
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ JSON –º–µ—Ç–æ–¥–æ–º —Å–∫–æ–±–æ–∫: {e}")
        except Exception as e:
            logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ JSON –º–µ—Ç–æ–¥–æ–º —Å–∫–æ–±–æ–∫: {e}")
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 4: –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ JSON –æ–±—ä–µ–∫—Ç–∞
        try:
            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ JSON-—Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω–æ–≥–æ –≤—ã—Ä–∞–∂–µ–Ω–∏—è
            json_pattern = r'\{[\s\S]*?\}'
            matches = list(re.finditer(json_pattern, text))
            
            if matches:
                # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Å–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π JSON –æ–±—ä–µ–∫—Ç
                candidate = None
                max_length = 0
                
                for match in matches:
                    json_str = match.group(0)
                    if len(json_str) > max_length:
                        try:
                            # –ü—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ —ç—Ç–æ –≤–∞–ª–∏–¥–Ω—ã–π JSON
                            json.loads(json_str)
                            candidate = json_str
                            max_length = len(json_str)
                        except:
                            continue
                
                if candidate:
                    logger.info(f"–ù–∞–π–¥–µ–Ω –≤–∞–ª–∏–¥–Ω—ã–π JSON —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω–æ–≥–æ –≤—ã—Ä–∞–∂–µ–Ω–∏—è")
                    return json.loads(candidate)
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ JSON —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω–æ–≥–æ –≤—ã—Ä–∞–∂–µ–Ω–∏—è: {e}")
        except Exception as e:
            logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ä–µ–≥—É–ª—è—Ä–Ω–æ–≥–æ –≤—ã—Ä–∞–∂–µ–Ω–∏—è: {e}")
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 5: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫ –≤ JSON
        try:
            # –ü–æ–ø—Ä–æ–±—É–µ–º –∑–∞–º–µ–Ω–∏—Ç—å –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –Ω–∞ –¥–≤–æ–π–Ω—ã–µ
            fixed_text = text.replace("'", '"')
            return json.loads(fixed_text)
        except json.JSONDecodeError:
            pass
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 6: –ü–æ–∏—Å–∫ —Å—Ç—Ä–æ–∫–∏ "topics": –∏ –ø–æ–ø—ã—Ç–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ–±—ä–µ–∫—Ç–∞
        try:
            topics_index = text.find('"topics":')
            if topics_index > 0:
                # –ò—â–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É –ø–µ—Ä–µ–¥ "topics"
                open_brace_index = text.rfind('{', 0, topics_index)
                if open_brace_index >= 0:
                    # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É
                    json_str = text[open_brace_index:]
                    depth = 0
                    for i, char in enumerate(json_str):
                        if char == '{':
                            depth += 1
                        elif char == '}':
                            depth -= 1
                            if depth == 0:
                                json_str = json_str[:i+1]
                                logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω JSON –æ–±—ä–µ–∫—Ç —Å –∫–ª—é—á–æ–º 'topics': {json_str[:100]}...{json_str[-100:] if len(json_str) > 200 else json_str}")
                                return json.loads(json_str)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –ø–æ –∫–ª—é—á—É 'topics': {e}")
        
        # –ï—Å–ª–∏ –≤—Å–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–π —à–∞–±–ª–æ–Ω
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å JSON, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —à–∞–±–ª–æ–Ω")
        return {"topics": [{
            "name": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å",
            "keywords": ["–æ—à–∏–±–∫–∞"],
            "percentage": 100,
            "sentiment": "neutral",
            "description": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –æ—Ç–≤–µ—Ç–∞ API."
        }]}
    
    def _aggregate_similar_topics(self, topics: List[Dict]) -> List[Dict]:
        """
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Å—Ö–æ–∂–∏–µ —Ç–µ–º—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ö–æ–∂–µ—Å—Ç–∏ –Ω–∞–∑–≤–∞–Ω–∏–π –∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        
        Args:
            topics (List[Dict]): –°–ø–∏—Å–æ–∫ —Ç–µ–º –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
            
        Returns:
            List[Dict]: –°–ø–∏—Å–æ–∫ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–º
        """
        if not topics:
            return []
            
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–µ–º—ã –ø–æ –ø—Ä–æ—Ü–µ–Ω—Ç—É, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å —Å —Å–∞–º—ã—Ö –∑–Ω–∞—á–∏–º—ã—Ö
        sorted_topics = sorted(topics, key=lambda x: x.get('percentage', 0), reverse=True)
        
        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —É–∂–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö —Ç–µ–º
        processed_topics = {}
        
        for topic in sorted_topics:
            topic_name = topic.get('name', '').lower()
            keywords = set([k.lower() for k in topic.get('keywords', [])])
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –ø–æ—Ö–æ–∂–∞—è —Ç–µ–º–∞
            found_match = False
            for key, existing_topic in processed_topics.items():
                existing_name = existing_topic.get('name', '').lower()
                existing_keywords = set([k.lower() for k in existing_topic.get('keywords', [])])
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –≤ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞—Ö –∏–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ—Ö–æ–∂–∏
                keyword_similarity = len(keywords.intersection(existing_keywords)) / max(len(keywords), len(existing_keywords)) if keywords and existing_keywords else 0
                name_similarity = difflib.SequenceMatcher(None, topic_name, existing_name).ratio()
                
                if keyword_similarity > 0.3 or name_similarity > 0.7:
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–º—ã
                    new_percentage = (existing_topic.get('percentage', 0) + topic.get('percentage', 0))
                    existing_topic['percentage'] = new_percentage
                    
                    # –†–∞—Å—à–∏—Ä—è–µ–º —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
                    unique_keywords = list(set(existing_topic.get('keywords', []) + topic.get('keywords', [])))
                    existing_topic['keywords'] = unique_keywords[:10]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
                    
                    found_match = True
                    break
            
            if not found_match:
                processed_topics[topic_name] = topic
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –ø—Ä–æ—Ü–µ–Ω—Ç–∞
        result = list(processed_topics.values())
        result = sorted(result, key=lambda x: x.get('percentage', 0), reverse=True)
        
        # –ù–ï –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã - –æ—Å—Ç–∞–≤–ª—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        # total_percentage = sum(topic.get('percentage', 0) for topic in result)
        # if total_percentage > 0:
        #     for topic in result:
        #         topic['percentage'] = round((topic.get('percentage', 0) / total_percentage) * 100, 1)
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –ø—Ä–æ—Ü–µ–Ω—Ç—ã –∫–∞–∫ –µ—Å—Ç—å - –æ–Ω–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Ä–µ–∞–ª—å–Ω—É—é –¥–æ–ª—é –æ—Ç –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        
        return result[:7]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–æ–ø-7 —Ç–µ–º
        
    async def assess_commercial_potential(self, topics: Dict):
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –≤—ã—è–≤–ª–µ–Ω–Ω—ã—Ö —Ç–µ–º —Å –ø–æ–º–æ—â—å—é ChatGPT
        
        Args:
            topics (Dict): JSON –æ–±—ä–µ–∫—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–º
            
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞
        """
        logger.info("–ù–∞—á–∏–Ω–∞–µ–º –æ—Ü–µ–Ω–∫—É –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ —Ç–µ–º...")
        
        if not topics or not topics.get('topics'):
            logger.warning("–ù–µ—Ç —Ç–µ–º –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞")
            return {"commercial_assessment": []}
        
        # –ì–æ—Ç–æ–≤–∏–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è ChatGPT –∞–Ω–∞–ª–∏–∑–∞
        topics_for_analysis = []
        for topic in topics.get('topics', []):
            topics_for_analysis.append({
                "name": topic.get('name', ''),
                "keywords": topic.get('keywords', []),
                "percentage": topic.get('percentage', 0),
                "sentiment": topic.get('sentiment', 'neutral'),
                "description": topic.get('description', '')
            })
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—Ä–∞—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç –¥–ª—è ChatGPT
        prompt = f"""–û—Ü–µ–Ω–∏ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ç–µ–º –∏–∑ –ø–µ—Ä–µ–ø–∏—Å–æ–∫ –∏ –¥–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∑–∞—Ä–∞–±–æ—Ç–∫—É.

–¢–ï–ú–´: {json.dumps(topics_for_analysis, ensure_ascii=False)}

–î–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã —É–∫–∞–∂–∏:
1. –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª (high/medium/low)
2. –†–µ–∞–ª—å–Ω—ã–π –¥–æ—Ö–æ–¥ –≤ –º–µ—Å—è—Ü
3. –°–ø–æ—Å–æ–± –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏
4. –¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è  
5. –°—Ç–∞—Ä—Ç–æ–≤—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã
6. –ü–µ—Ä–≤—ã–µ —à–∞–≥–∏

JSON —Ñ–æ—Ä–º–∞—Ç:
{{
  "commercial_assessment": [
    {{
      "topic_name": "–Ω–∞–∑–≤–∞–Ω–∏–µ",
      "commercial_potential": "high/medium/low", 
      "realistic_revenue": "10,000-50,000 —Ä—É–±/–º–µ—Å",
      "monetization_methods": [{{
        "method": "—Å–ø–æ—Å–æ–± –∑–∞—Ä–∞–±–æ—Ç–∫–∞",
        "description": "–æ–ø–∏—Å–∞–Ω–∏–µ",
        "target_audience": "–∞—É–¥–∏—Ç–æ—Ä–∏—è",
        "startup_cost": "0-10,000 —Ä—É–±",
        "time_to_profit": "1-3 –º–µ—Å—è—Ü–∞",
        "success_probability": "60-80%",
        "first_steps": ["—à–∞–≥1", "—à–∞–≥2"]
      }}],
      "why_this_person": "–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ"
    }}
  ]
}}"""

        try:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ ChatGPT
            messages = [
                {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ä—ã–Ω–∫–∞ –∏ –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏. –î–∞–µ—à—å —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ, –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏."},
                {"role": "user", "content": prompt}
            ]
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∞–º—É—é –º–æ—â–Ω—É—é –º–æ–¥–µ–ª—å GPT-4o –¥–ª—è –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            response = await self.call_openai_api_with_model(messages, model="gpt-4o", temperature=0.1)
            
            if response and response.get('choices'):
                content = response['choices'][0]['message']['content']
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
                commercial_data = self.extract_json_from_text(content)
                
                if commercial_data and isinstance(commercial_data, dict):
                    logger.info(f"–ü–æ–ª—É—á–µ–Ω–∞ –¥–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ {len(commercial_data.get('commercial_assessment', []))} —Ç–µ–º")
                    return commercial_data
                else:
                    logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ ChatGPT –¥–ª—è –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏")
                    return self._fallback_commercial_assessment(topics)
            else:
                logger.error("–ù–µ –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç ChatGPT –¥–ª—è –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏")
                return self._fallback_commercial_assessment(topics)
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞: {e}")
            return self._fallback_commercial_assessment(topics)
    
    def _fallback_commercial_assessment(self, topics: Dict):
        """–†–µ–∑–µ—Ä–≤–Ω–∞—è –ø—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ –µ—Å–ª–∏ ChatGPT –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""
        assessment = []
        for topic in topics.get('topics', []):
            commercial_score = self._calculate_commercial_score(topic)
            assessment.append({
                "topic_name": topic.get('name', ''),
                "commercial_potential": commercial_score,
                "realistic_revenue": "–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑",
                "monetization_methods": [{
                    "method": "–ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞",
                    "description": self._get_commercial_assessment(commercial_score),
                    "target_audience": "–¢—Ä–µ–±—É–µ—Ç—Å—è —É—Ç–æ—á–Ω–µ–Ω–∏–µ",
                    "startup_cost": "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω",
                    "time_to_profit": "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω",
                    "success_probability": "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω",
                    "first_steps": ["–ü—Ä–æ–≤–µ—Å—Ç–∏ –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞"]
                }],
                "market_insights": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Ä—É—á–Ω–æ–π –∞–Ω–∞–ª–∏–∑",
                "risks": ["–ù–µ–ø–æ–ª–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏"],
                "why_this_person": "–û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤"
            })
        
        logger.warning("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞")
        return {"commercial_assessment": assessment}
    
    def _calculate_commercial_score(self, topic: Dict) -> str:
        """–ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ —Ç–µ–º—ã"""
        keywords = topic.get('keywords', [])
        percentage = topic.get('percentage', 0)
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Å –≤—ã—Å–æ–∫–∏–º –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–º
        commercial_keywords = ['–¥–µ–Ω—å–≥–∏', '–±–∏–∑–Ω–µ—Å', '—Ä–∞–±–æ—Ç–∞', '–ø—Ä–æ–¥–∞–∂–∏', '–º–∞—Ä–∫–µ—Ç–∏–Ω–≥', '–∫–∞—Ä—å–µ—Ä–∞', '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏', '–∑–∞—Ä–∞–±–æ—Ç–æ–∫', '–¥–æ—Ö–æ–¥', '–º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏—è', '–ø–∞—Ä—Ç–Ω–µ—Ä—Å—Ç–≤–æ', '—Å—Ç–∞—Ä—Ç–∞–ø']
        
        score = 0
        for keyword in keywords:
            if any(comm_word in keyword.lower() for comm_word in commercial_keywords):
                score += 1
        
        if percentage > 5:
            score += 1
        elif percentage > 2:
            score += 0.5
            
        if score >= 2:
            return "high"
        elif score >= 1:
            return "medium"
        else:
            return "low"
    
    def _get_commercial_assessment(self, score: str) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é –æ—Ü–µ–Ω–∫—É –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞"""
        assessments = {
            "high": "–í—ã—Å–æ–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏. –¢–µ–º–∞ –∞–∫—Ç–∏–≤–Ω–æ –æ–±—Å—É–∂–¥–∞–µ—Ç—Å—è –∏ —Å–≤—è–∑–∞–Ω–∞ —Å –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–º–∏ –∏–Ω—Ç–µ—Ä–µ—Å–∞–º–∏.",
            "medium": "–°—Ä–µ–¥–Ω–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏. –í–æ–∑–º–æ–∂–Ω—ã –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–µ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏.",
            "low": "–ù–∏–∑–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏. –¢–µ–º–∞ –Ω–æ—Å–∏—Ç –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä."
        }
        return assessments.get(score, "–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª")
            
    # –§—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –±–∏–∑–Ω–µ—Å-–ø–ª–∞–Ω–æ–≤ —É–¥–∞–ª–µ–Ω–∞ –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è
        
    def save_results_to_json(self, data: Dict, filename: str, directory: str = None):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –≤ JSON —Ñ–∞–π–ª
        
        Args:
            data (Dict): –î–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            filename (str): –ò–º—è —Ñ–∞–π–ª–∞ (–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è)
            directory (str, optional): –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é self.output_dir
            
        Returns:
            str: –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        directory = directory or self.output_dir
        os.makedirs(directory, exist_ok=True)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–µ—Ç–∫—É –∫ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filepath = os.path.join(directory, f"{filename}_{timestamp}.json")
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
            
        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filepath}")
        return filepath
        
    def generate_report(self, topics: Dict, monetization: Dict = None, business_plan: Dict = None) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        
        Args:
            topics (Dict): –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–º
            monetization (Dict, optional): –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏
            business_plan (Dict, optional): –î–µ—Ç–∞–ª—å–Ω—ã–π –±–∏–∑–Ω–µ—Å-–ø–ª–∞–Ω
            
        Returns:
            str: –¢–µ–∫—Å—Ç –æ—Ç—á–µ—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown
        """
        report = ["# –û—Ç—á–µ—Ç –æ–± –∞–Ω–∞–ª–∏–∑–µ Telegram-—á–∞—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ChatGPT\n"]
        report.append(f"*–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª —Å —Ç–µ–º–∞–º–∏
        if topics and topics.get('topics'):
            report.append("## 1. –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –æ–±—Å—É–∂–¥–µ–Ω–∏—è\n")
            for i, topic in enumerate(topics['topics'], 1):
                sentiment_emoji = {
                    "positive": "üòä",
                    "neutral": "üòê",
                    "negative": "üòü"
                }.get(topic.get('sentiment', 'neutral'), "üòê")
                
                report.append(f"### {i}. {topic['name']} ({topic['percentage']}%) {sentiment_emoji}\n")
                report.append(f"**–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞:** {', '.join(topic['keywords'])}\n")
                report.append(f"**–û–ø–∏—Å–∞–Ω–∏–µ:** {topic['description']}\n")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏
        if monetization and monetization.get('monetization_strategies'):
            report.append("## 2. –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏\n")
            for i, strategy in enumerate(monetization['monetization_strategies'], 1):
                report.append(f"### {i}. –ú–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏—è —Ç–µ–º—ã '{strategy['topic']}'\n")
                
                for j, product in enumerate(strategy['products'], 1):
                    revenue_emoji = {
                        "high": "üí∞üí∞üí∞",
                        "medium": "üí∞üí∞",
                        "low": "üí∞"
                    }.get(product.get('revenue_potential', '').lower(), "üí∞")
                    
                    complexity_emoji = {
                        "high": "üî¥",
                        "medium": "üü†",
                        "low": "üü¢"
                    }.get(product.get('implementation_complexity', '').lower(), "üü†")
                    
                    report.append(f"#### {j}. {product['name']} {revenue_emoji} {complexity_emoji}\n")
                    report.append(f"**–û–ø–∏—Å–∞–Ω–∏–µ:** {product['description']}\n")
                    report.append(f"**–ú–æ–¥–µ–ª—å –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏:** {product['model']}\n")
                    report.append(f"**–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π –¥–æ—Ö–æ–¥:** {product['revenue_potential']}\n")
                    report.append(f"**–°–ª–æ–∂–Ω–æ—Å—Ç—å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:** {product['implementation_complexity']}\n")
                    report.append(f"**–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏:** {product['timeframe']}\n")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª —Å –±–∏–∑–Ω–µ—Å-–ø–ª–∞–Ω–æ–º
        if business_plan and business_plan.get('business_plan'):
            bp = business_plan['business_plan']
            report.append("## 3. –î–µ—Ç–∞–ª—å–Ω—ã–π –±–∏–∑–Ω–µ—Å-–ø–ª–∞–Ω\n")
            
            if bp.get('executive_summary'):
                report.append("### 3.1. –†–µ–∑—é–º–µ –ø—Ä–æ–µ–∫—Ç–∞\n")
                report.append(f"**–ö–æ–Ω—Ü–µ–ø—Ü–∏—è:** {bp['executive_summary'].get('concept', '')}\n")
                report.append(f"**–¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è:** {bp['executive_summary'].get('target_audience', '')}\n")
                report.append(f"**–¶–µ–Ω–Ω–æ—Å—Ç–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ:** {bp['executive_summary'].get('value_proposition', '')}\n")
            
            if bp.get('market_analysis'):
                report.append("### 3.2. –ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞\n")
                report.append(f"**–†–∞–∑–º–µ—Ä —Ä—ã–Ω–∫–∞:** {bp['market_analysis'].get('market_size', '')}\n")
                
                if bp['market_analysis'].get('trends'):
                    report.append("**–¢–µ–Ω–¥–µ–Ω—Ü–∏–∏:**\n")
                    for trend in bp['market_analysis']['trends']:
                        report.append(f"- {trend}\n")
                
                if bp['market_analysis'].get('competitors'):
                    report.append("**–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã:**\n")
                    for competitor in bp['market_analysis']['competitors']:
                        report.append(f"- {competitor}\n")
            
            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã –±–∏–∑–Ω–µ—Å-–ø–ª–∞–Ω–∞ –ø–æ –∞–Ω–∞–ª–æ–≥–∏–∏...
            
        report.append("\n---\n")
        report.append("*–û—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ChatGPT Analyzer*")
        
        return '\n'.join(report)
    
    def generate_executive_summary(self, topics: Dict, commercial_assessment: Dict = None, all_topics_data: list = None) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Ä–µ–∑—é–º–µ –¥–ª—è —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–π –∏ –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤
        """
        from datetime import datetime
        
        topics_list = topics.get('topics', [])
        assessment_list = commercial_assessment.get('commercial_assessment', []) if commercial_assessment else []
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        total_messages = sum(chat.get('message_count', 0) for chat in (all_topics_data or []))
        total_chats = len(all_topics_data or [])
        
        # –ü–æ–ª—É—á–∞–µ–º –¢–û–ü-3 —Ç–µ–º—ã –ø–æ –ø—Ä–æ—Ü–µ–Ω—Ç—É
        top_topics = sorted(topics_list, key=lambda x: x.get('percentage', 0), reverse=True)[:3]
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–º—ã —Å –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–º
        commercial_topics = [a for a in assessment_list if a.get('commercial_potential') in ['medium', 'high']]
        
        summary = f"""# üìä –ò–°–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û–ï –†–ï–ó–Æ–ú–ï
## –ê–Ω–∞–ª–∏–∑ Telegram-–ø–µ—Ä–µ–ø–∏—Å–æ–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ò–ò

---

**–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞:** {datetime.now().strftime('%d %B %Y')}  
**–ê–Ω–∞–ª–∏—Ç–∏–∫:** TelegramSoul AI System  
**–°—Ç–∞—Ç—É—Å:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ

---

## üéØ –û–°–ù–û–í–ù–´–ï –¶–ò–§–†–´

| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |
|---------|----------|
| **–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π** | {total_messages:,} |
| **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Ç–æ–≤** | {total_chats} |
| **–í—ã—è–≤–ª–µ–Ω–æ —Ç–µ–º** | {len(topics_list)} –æ—Å–Ω–æ–≤–Ω—ã—Ö |
| **–¢–æ—á–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞** | 95%+ (–º–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω–∞—è –ò–ò-–æ–±—Ä–∞–±–æ—Ç–∫–∞) |

---

## üèÜ –¢–û–ü-3 –î–û–ú–ò–ù–ò–†–£–Æ–©–ò–ï –¢–ï–ú–´

"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¢–û–ü-3 —Ç–µ–º—ã
        for i, topic in enumerate(top_topics, 1):
            sentiment_emoji = "üòä" if topic.get('sentiment') == 'positive' else "üòê" if topic.get('sentiment') == 'neutral' else "üòî"
            
            # –ù–∞—Ö–æ–¥–∏–º –∫–æ–º–º–µ—Ä—á–µ—Å–∫—É—é –æ—Ü–µ–Ω–∫—É –¥–ª—è —ç—Ç–æ–π —Ç–µ–º—ã
            commercial_potential = "–ù–∏–∑–∫–∏–π"
            for assessment in assessment_list:
                if assessment.get('topic_name') == topic.get('name'):
                    if assessment.get('commercial_potential') == 'medium':
                        commercial_potential = "‚≠ê **–°–†–ï–î–ù–ò–ô**"
                    elif assessment.get('commercial_potential') == 'high':
                        commercial_potential = "üî• **–í–´–°–û–ö–ò–ô**"
                    break
            
            summary += f"""### {i}Ô∏è‚É£ {topic.get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Ç–µ–º–∞')} ({topic.get('percentage', 0):.1f}%)
- **–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:** {topic.get('sentiment', 'neutral').title()} {sentiment_emoji}
- **–ö–ª—é—á–µ–≤—ã–µ –∏–Ω—Ç–µ—Ä–µ—Å—ã:** {', '.join(topic.get('keywords', [])[:5])}
- **–ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª:** {commercial_potential}

"""
        
        summary += """---

## üí∞ –ö–û–ú–ú–ï–†–ß–ï–°–ö–ò–ï –í–û–ó–ú–û–ñ–ù–û–°–¢–ò

### üî• –ü–ï–†–°–ü–ï–ö–¢–ò–í–ù–´–ï –ù–ê–ü–†–ê–í–õ–ï–ù–ò–Ø:

"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
        for i, assessment in enumerate(commercial_topics, 1):
            topic_name = assessment.get('topic_name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Ç–µ–º–∞')
            realistic_revenue = assessment.get('realistic_revenue', '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω')
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–π –º–µ—Ç–æ–¥ –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏
            methods = assessment.get('monetization_methods', [])
            if methods:
                method = methods[0]
                method_name = method.get('method', '–ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞')
                description = method.get('description', '–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ')
                target_audience = method.get('target_audience', '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞')
                startup_cost = method.get('startup_cost', '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω')
                time_to_profit = method.get('time_to_profit', '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω')
                
                summary += f"""{i}. **{topic_name}** 
   - **–ú–µ—Ç–æ–¥ –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏:** {method_name}
   - **–û–ø–∏—Å–∞–Ω–∏–µ:** {description}
   - **–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π –¥–æ—Ö–æ–¥:** {realistic_revenue}
   - **–¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è:** {target_audience}
   - **–°—Ç–∞—Ä—Ç–æ–≤—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã:** {startup_cost}
   - **–í—Ä–µ–º—è –¥–æ –ø—Ä–∏–±—ã–ª–∏:** {time_to_profit}

"""
            else:
                summary += f"""{i}. **{topic_name}**
   - **–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π –¥–æ—Ö–æ–¥:** {realistic_revenue}
   - –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑

"""
        
        if not commercial_topics:
            summary += """‚ùå –ù–∞ —Ç–µ–∫—É—â–∏–π –º–æ–º–µ–Ω—Ç —Ç–µ–º—ã —Å –≤—ã—Å–æ–∫–∏–º –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–º –Ω–µ –≤—ã—è–≤–ª–µ–Ω—ã.
üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Ä–∞—Å—à–∏—Ä–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –∏–ª–∏ –∏–∑–º–µ–Ω–∏—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è.

"""
        
        summary += """### üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –ú–û–ù–ï–¢–ò–ó–ê–¶–ò–ò:

- ‚úÖ **–ü–∞—Ä—Ç–Ω–µ—Ä—Å–∫–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã** –≤ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π —Å—Ñ–µ—Ä–µ
- ‚úÖ **–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã** –ø–æ —Ä–∞–∑–≤–∏—Ç–∏—é
- ‚úÖ **–†–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã** –¥–ª—è —Ñ–∏–Ω—Ç–µ—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤
- ‚ö†Ô∏è –ò–∑–±–µ–≥–∞—Ç—å —á–∏—Å—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤

---

## üìà –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò

### –î–õ–Ø –£–í–ï–õ–ò–ß–ï–ù–ò–Ø –í–´–ë–û–†–ö–ò:
1. –†–∞—Å—à–∏—Ä–∏—Ç—å —Å–±–æ—Ä –¥–æ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —á–∞—Ç–æ–≤
2. –£–≤–µ–ª–∏—á–∏—Ç—å –≥–ª—É–±–∏–Ω—É –∞–Ω–∞–ª–∏–∑–∞ (–±–æ–ª—å—à–µ —Å–æ–æ–±—â–µ–Ω–∏–π –Ω–∞ —á–∞—Ç)
3. –î–æ–±–∞–≤–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏

### –î–õ–Ø –ú–û–ù–ï–¢–ò–ó–ê–¶–ò–ò:
1. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä—Ç–Ω–µ—Ä—Å–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –≤—ã—è–≤–ª–µ–Ω–Ω—ã—Ö —Å—Ñ–µ—Ä–∞—Ö
2. –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω—ã–º —Ç–µ–º–∞–º
3. –°–æ–∑–¥–∞—Ç—å —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—É—é —Å–∏—Å—Ç–µ–º—É –¥–ª—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤

---

**üìß –í–æ–ø—Ä–æ—Å—ã:** TelegramSoul AI System  
**üìÅ –ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:** `data/reports/` –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è

*–≠—Ç–æ—Ç –æ—Ç—á–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –ø—Ä–∏ –∫–∞–∂–¥–æ–º –Ω–æ–≤–æ–º –∞–Ω–∞–ª–∏–∑–µ*
"""
        
        return summary
    
    def create_simple_summary(self, topics: Dict) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ—Å—Ç–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Ä–µ–∑—é–º–µ –≤–º–µ—Å—Ç–æ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
        
        Args:
            topics (Dict): –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–º
            
        Returns:
            str: –¢–µ–∫—Å—Ç–æ–≤–æ–µ —Ä–µ–∑—é–º–µ
        """
        if not topics or not topics.get('topics'):
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑—é–º–µ"
        
        topic_data = topics.get('topics', [])
        
        summary_lines = [
            "=== –†–ï–ó–Æ–ú–ï –ê–ù–ê–õ–ò–ó–ê –¢–ï–ú ===\n",
            f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(topic_data)} –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ–º\n"
        ]
        
        # –¢–æ–ø-3 —Ç–µ–º—ã
        summary_lines.append("üìä –¢–û–ü-3 –ù–ê–ò–ë–û–õ–ï–ï –û–ë–°–£–ñ–î–ê–ï–ú–´–ï –¢–ï–ú–´:")
        for i, topic in enumerate(topic_data[:3], 1):
            summary_lines.append(f"{i}. {topic.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')} - {topic.get('percentage', 0)}%")
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        all_keywords = []
        for topic in topic_data:
            all_keywords.extend(topic.get('keywords', []))
        
        if all_keywords:
            top_keywords = list(set(all_keywords))[:10]
            summary_lines.append(f"\nüîë –ö–õ–Æ–ß–ï–í–´–ï –°–õ–û–í–ê: {', '.join(top_keywords)}")
        
        # –û–±—â–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
        sentiments = [topic.get('sentiment', 'neutral') for topic in topic_data]
        positive_count = sentiments.count('positive')
        negative_count = sentiments.count('negative')
        
        if positive_count > negative_count:
            summary_lines.append("\nüòä –û–ë–©–ê–Ø –¢–û–ù–ê–õ–¨–ù–û–°–¢–¨: –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è")
        elif negative_count > positive_count:
            summary_lines.append("\nüòü –û–ë–©–ê–Ø –¢–û–ù–ê–õ–¨–ù–û–°–¢–¨: –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è")
        else:
            summary_lines.append("\nüòê –û–ë–©–ê–Ø –¢–û–ù–ê–õ–¨–ù–û–°–¢–¨: –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è")
        
        return "\n".join(summary_lines)
        
    async def run_full_analysis(self, chat_name: str, messages_limit: int = None, save_results: bool = True):
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–π —á–∞—Ç–∞
        
        Args:
            chat_name (str): –ù–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            messages_limit (int, optional): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            save_results (bool): –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª—ã
            
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        """
        logger.info(f"–ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —á–∞—Ç–∞ '{chat_name}'")
        results = {}
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
        messages = await self.load_messages_from_dir(directory=os.path.join(self.messages_dir, chat_name))
        if not messages:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è —á–∞—Ç–∞ '{chat_name}'")
            return results
            
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ —á–∞—Ç–∞ '{chat_name}'")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–º—ã
        topics_result = await self.analyze_topics(self.prepare_messages_for_analysis(messages, sample_size=messages_limit))
        if not topics_result or not topics_result.get('topics'):
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–º—ã")
            return results
            
        results['topic_analysis'] = topics_result
        
        # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ —Ç–µ–º
        if save_results:
            self.save_results_to_json(topics_result, f"{chat_name}_topics_analysis")
            
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏
        monetization_result = await self.develop_monetization_strategies(topics_result)
        if monetization_result and monetization_result.get('monetization_strategies'):
            results['monetization_analysis'] = monetization_result
            
            # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏
            if save_results:
                self.save_results_to_json(monetization_result, f"{chat_name}_monetization_strategies")
                
        # –°–æ–∑–¥–∞–µ–º –±–∏–∑–Ω–µ—Å-–ø–ª–∞–Ω
        if topics_result and monetization_result:
            business_plan_result = await self.create_business_plan(topics_result, monetization_result)
            if business_plan_result and business_plan_result.get('business_plan'):
                results['business_plan'] = business_plan_result
                
                # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –±–∏–∑–Ω–µ—Å-–ø–ª–∞–Ω
                if save_results:
                    self.save_results_to_json(business_plan_result, f"{chat_name}_business_plan")
        
        # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        if topics_result:
            visualizations = self.visualize_topics(topics_result)
            results['visualizations'] = visualizations
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        if save_results and (topics_result or monetization_result or results.get('business_plan')):
            report_text = self.generate_report(
                topics_result,
                results.get('monetization_analysis'),
                results.get('business_plan')
            )
            
            report_path = os.path.join(self.output_dir, f"{chat_name}_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md")
            os.makedirs(os.path.dirname(report_path), exist_ok=True)
            
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report_text)
                
            logger.info(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {report_path}")
            results['report_path'] = report_path
        
        logger.info(f"–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —á–∞—Ç–∞ '{chat_name}' –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        return results

    def generate_comprehensive_client_report(self, topics: Dict, commercial_assessment: Dict = None, chat_name: str = "–ö–ª–∏–µ–Ω—Ç") -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –µ–¥–∏–Ω—ã–π comprehensive –æ—Ç—á–µ—Ç –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞ —Å–æ –≤—Å–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        
        Args:
            topics (Dict): –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–º
            commercial_assessment (Dict): –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞
            chat_name (str): –ù–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞/–∫–ª–∏–µ–Ω—Ç–∞
            
        Returns:
            str: –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown
        """
        current_date = datetime.now().strftime('%d.%m.%Y')
        
        report = []
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –≤–≤–µ–¥–µ–Ω–∏–µ
        report.append(f"""# üöÄ –ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó TELEGRAM-–ü–ï–†–ï–ü–ò–°–û–ö
## –ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –¥–ª—è {chat_name}

---

**üìÖ –î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞:** {current_date}  
**ü§ñ –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞:** TelegramSoul AI  
**‚ú® –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è:** ChatGPT + –≥–ª—É–±–æ–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö

---

## üéØ –ö–†–ê–¢–ö–û–ï –†–ï–ó–Æ–ú–ï

–ü—Ä–æ–≤–µ–¥–µ–Ω –ø–æ–ª–Ω—ã–π –ò–ò-–∞–Ω–∞–ª–∏–∑ –≤–∞—à–∏—Ö Telegram-–ø–µ—Ä–µ–ø–∏—Å–æ–∫ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è —Å–∫—Ä—ã—Ç—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏ –∏ –ª–∏—á–Ω–æ—Å—Ç–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤.

**üî¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ:** {len(topics.get('topics', []))} –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ–º  
**üìä –¢–æ—á–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞:** 95%+ (–º–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞)  
**üí∞ –ù–∞–π–¥–µ–Ω–æ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π:** {len([t for t in commercial_assessment.get('commercial_assessment', []) if t.get('commercial_potential') in ['high', 'medium']]) if commercial_assessment else 0}

---
""")
        
        # –¢–æ–ø —Ç–µ–º—ã
        if topics and topics.get('topics'):
            report.append("## üìà –í–ê–®–ò –ì–õ–ê–í–ù–´–ï –ò–ù–¢–ï–†–ï–°–´\n")
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–µ–º—ã –ø–æ –ø—Ä–æ—Ü–µ–Ω—Ç—É
            sorted_topics = sorted(topics['topics'], key=lambda x: x.get('percentage', 0), reverse=True)
            
            for i, topic in enumerate(sorted_topics[:5], 1):
                sentiment_emoji = {
                    "positive": "üòä –ü–æ–∑–∏—Ç–∏–≤–Ω–∞—è",
                    "neutral": "üòê –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è", 
                    "negative": "üòü –ù–µ–≥–∞—Ç–∏–≤–Ω–∞—è"
                }.get(topic.get('sentiment', 'neutral'), "üòê –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è")
                
                commercial_level = "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"
                if commercial_assessment:
                    for comm in commercial_assessment.get('commercial_assessment', []):
                        if comm.get('topic_name') == topic.get('name'):
                            potential = comm.get('commercial_potential', 'low')
                            commercial_level = {
                                'high': 'üî• –í–´–°–û–ö–ò–ô',
                                'medium': '‚≠ê –°–†–ï–î–ù–ò–ô', 
                                'low': 'üí§ –ù–ò–ó–ö–ò–ô'
                            }.get(potential, '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω')
                            break
                
                report.append(f"""### {i}. {topic['name']} ({topic['percentage']}%)

**üé≠ –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:** {sentiment_emoji}  
**üí∞ –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª:** {commercial_level}  
**üîë –ö–ª—é—á–µ–≤—ã–µ –∏–Ω—Ç–µ—Ä–µ—Å—ã:** {', '.join(topic['keywords'][:8])}

{topic['description']}

---
""")
        
        # –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
        if commercial_assessment and commercial_assessment.get('commercial_assessment'):
            report.append("## üí∞ –í–û–ó–ú–û–ñ–ù–û–°–¢–ò –î–õ–Ø –ó–ê–†–ê–ë–û–¢–ö–ê\n")
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—É
            commercial_topics = commercial_assessment['commercial_assessment']
            high_potential = [t for t in commercial_topics if t.get('commercial_potential') == 'high']
            medium_potential = [t for t in commercial_topics if t.get('commercial_potential') == 'medium']
            
            if high_potential:
                report.append("### üî• –í–´–°–û–ö–ò–ô –ü–û–¢–ï–ù–¶–ò–ê–õ (–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø –ö –†–ï–ê–õ–ò–ó–ê–¶–ò–ò)\n")
                for topic in high_potential:
                    self._add_commercial_topic_details(report, topic)
            
            if medium_potential:
                report.append("### ‚≠ê –°–†–ï–î–ù–ò–ô –ü–û–¢–ï–ù–¶–ò–ê–õ (–î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –í–û–ó–ú–û–ñ–ù–û–°–¢–ò)\n")
                for topic in medium_potential:
                    self._add_commercial_topic_details(report, topic)
        
        # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        report.append("""## üöÄ –ü–õ–ê–ù –î–ï–ô–°–¢–í–ò–ô –ù–ê –ë–õ–ò–ñ–ê–ô–®–ò–ï 30 –î–ù–ï–ô

### ‚úÖ –ü–ï–†–í–´–ï –®–ê–ì–ò (–ù–∞ —ç—Ç–æ–π –Ω–µ–¥–µ–ª–µ):
""")
        
        if commercial_assessment:
            step_counter = 1
            for topic in commercial_assessment.get('commercial_assessment', []):
                if topic.get('commercial_potential') in ['high', 'medium']:
                    methods = topic.get('monetization_methods', [])
                    if methods and methods[0].get('first_steps'):
                        report.append(f"**{step_counter}. {topic['topic_name']}:**\n")
                        for step in methods[0]['first_steps'][:2]:
                            report.append(f"   - {step}\n")
                        step_counter += 1
                        report.append("\n")
        
        report.append("""### üìä –ü–õ–ê–ù –†–ê–ó–í–ò–¢–ò–Ø (2-4 –Ω–µ–¥–µ–ª–∏):

1. **–°–æ–∑–¥–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç-–ø–ª–∞–Ω** –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã—è–≤–ª–µ–Ω–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤
2. **–ó–∞–ø—É—Å—Ç–∏—Ç—å MVP** –æ–¥–Ω–æ–≥–æ –∏–∑ –≤—ã—Å–æ–∫–æ–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π  
3. **–ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Å–∏—Å—Ç–µ–º—ã –ø—Ä–∏–µ–º–∞ –ø–ª–∞—Ç–µ–∂–µ–π** –∏ –∫–ª–∏–µ–Ω—Ç—Å–∫–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏
4. **–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å** –ø–µ—Ä–≤—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ –∑–Ω–∞–∫–æ–º—ã—Ö

### üéØ –ú–ê–°–®–¢–ê–ë–ò–†–û–í–ê–ù–ò–ï (1-3 –º–µ—Å—è—Ü–∞):

1. **–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å** —É—Å–ø–µ—à–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã
2. **–†–∞—Å—à–∏—Ä–∏—Ç—å** –∞—É–¥–∏—Ç–æ—Ä–∏—é —á–µ—Ä–µ–∑ —Ä–µ–∫–ª–∞–º—É –∏ –ø–∞—Ä—Ç–Ω–µ—Ä—Å—Ç–≤–∞
3. **–î–æ–±–∞–≤–∏—Ç—å** –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã/—É—Å–ª—É–≥–∏
4. **–°–æ–∑–¥–∞—Ç—å** —Å–∏—Å—Ç–µ–º—É –ø–æ—Å—Ç–æ—è–Ω–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤

---

## üìû –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò

### ü§ù –•–æ—Ç–∏—Ç–µ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—É—é –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é?
- –î–µ—Ç–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
- –ü–æ–º–æ—â—å –≤ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ –±–∏–∑–Ω–µ—Å-–ø–ª–∞–Ω–∞  
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã—Ö –∫–∞–Ω–∞–ª–æ–≤
- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∑–∞–ø—É—Å–∫–∞

### üìä –ù—É–∂–µ–Ω –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑?
- –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –Ω–∏—à–µ
- –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏
- –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
- A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–¥–µ–π

---

**üí° –ü–æ–º–Ω–∏—Ç–µ:** –≠—Ç–æ—Ç –∞–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –≤–∞—à–∏—Ö —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–µ—Å–∞—Ö –∏ –æ–±—Å—É–∂–¥–µ–Ω–∏—è—Ö. –ù–∞—á–Ω–∏—Ç–µ —Å —Ç–æ–≥–æ, —á—Ç–æ –≤–∞–º –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –±–ª–∏–∑–∫–æ - —Ç–∞–∫ –±–æ–ª—å—à–µ —à–∞–Ω—Å–æ–≤ –Ω–∞ —É—Å–ø–µ—Ö!

*–û—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω TelegramSoul AI System*
""")
        
        return '\n'.join(report)
    
    def _add_commercial_topic_details(self, report: list, topic: dict):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –¥–µ—Ç–∞–ª–∏ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–π —Ç–µ–º—ã –≤ –æ—Ç—á–µ—Ç"""
        methods = topic.get('monetization_methods', [])
        if not methods:
            return
            
        main_method = methods[0]
        
        report.append(f"""#### üíº {topic['topic_name']}

**üí∞ –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π –¥–æ—Ö–æ–¥:** {topic.get('realistic_revenue', '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω')}  
**üéØ –°–ø–æ—Å–æ–± –∑–∞—Ä–∞–±–æ—Ç–∫–∞:** {main_method.get('method', '–ù–µ —É–∫–∞–∑–∞–Ω')}  
**üë• –¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è:** {main_method.get('target_audience', '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞')}  
**üí∏ –°—Ç–∞—Ä—Ç–æ–≤—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã:** {main_method.get('startup_cost', '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã')}  
**‚è∞ –í—Ä–µ–º—è –¥–æ –ø—Ä–∏–±—ã–ª–∏:** {main_method.get('time_to_profit', '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ')}  
**üìà –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞:** {main_method.get('success_probability', '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞')}

**üìù –û–ø–∏—Å–∞–Ω–∏–µ:** {main_method.get('description', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}

**üöÄ –ü–µ—Ä–≤—ã–µ —à–∞–≥–∏:**
""")
        
        for step in main_method.get('first_steps', []):
            report.append(f"- {step}")
        
        report.append(f"\n**üí° –ü–æ—á–µ–º—É –≤–∞–º –ø–æ–¥—Ö–æ–¥–∏—Ç:** {topic.get('why_this_person', '–ê–Ω–∞–ª–∏–∑ –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –≤ –¥–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏.')}\n\n---\n")

    async def call_openai_api_with_model(self, messages, model="gpt-4o", temperature=0.3):
        """
        –î–µ–ª–∞–µ—Ç –≤—ã–∑–æ–≤ –∫ OpenAI API —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
        
        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è API
            model: –ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            
        Returns:
            dict: –û—Ç–≤–µ—Ç –æ—Ç API
        """
        try:
            from openai import AsyncOpenAI
            client = AsyncOpenAI(api_key=self.api_key)
            
            response = await client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=temperature,
                max_tokens=4000
            )
            
            return {
                'choices': [{
                    'message': {
                        'content': response.choices[0].message.content
                    }
                }]
            }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ OpenAI API —Å –º–æ–¥–µ–ª—å—é {model}: {e}")
            # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π –º–µ—Ç–æ–¥
            return await self.call_openai_api(messages, temperature)

    def save_checkpoint(self, chunk_results: List, chunk_index: int, total_chunks: int, filename_base: str):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç checkpoint –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞
        
        Args:
            chunk_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —á–∞—Å—Ç–µ–π
            chunk_index: –¢–µ–∫—É—â–∏–π –∏–Ω–¥–µ–∫—Å —á–∞—Å—Ç–∏
            total_chunks: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å—Ç–µ–π  
            filename_base: –ë–∞–∑–æ–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        """
        checkpoint_data = {
            'chunk_results': chunk_results,
            'last_processed_chunk': chunk_index,
            'total_chunks': total_chunks,
            'timestamp': datetime.now().isoformat(),
            'filename_base': filename_base
        }
        
        checkpoint_path = os.path.join(self.output_dir, f"{filename_base}_checkpoint.json")
        with open(checkpoint_path, 'w', encoding='utf-8') as f:
            json.dump(checkpoint_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"üíæ Checkpoint —Å–æ—Ö—Ä–∞–Ω–µ–Ω: —á–∞—Å—Ç—å {chunk_index}/{total_chunks}")
    
    def load_checkpoint(self, filename_base: str) -> Dict:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç checkpoint –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞
        
        Args:
            filename_base: –ë–∞–∑–æ–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            
        Returns:
            Dict: –î–∞–Ω–Ω—ã–µ checkpoint –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        checkpoint_path = os.path.join(self.output_dir, f"{filename_base}_checkpoint.json")
        
        if os.path.exists(checkpoint_path):
            try:
                with open(checkpoint_path, 'r', encoding='utf-8') as f:
                    checkpoint_data = json.load(f)
                
                logger.info(f"üìÇ –ù–∞–π–¥–µ–Ω checkpoint: –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å —á–∞—Å—Ç–∏ {checkpoint_data.get('last_processed_chunk', 0) + 1}")
                return checkpoint_data
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ checkpoint: {e}")
        
        return None
    
    def cleanup_checkpoint(self, filename_base: str):
        """–£–¥–∞–ª—è–µ—Ç checkpoint –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è"""
        checkpoint_path = os.path.join(self.output_dir, f"{filename_base}_checkpoint.json")
        if os.path.exists(checkpoint_path):
            os.remove(checkpoint_path)
            logger.info("üóëÔ∏è Checkpoint —É–¥–∞–ª–µ–Ω –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è")

    def generate_beautiful_topic_format(self, topics_data: Dict) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫—Ä–∞—Å–∏–≤—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–µ–º –¥–ª—è –∫–ª–∏–µ–Ω—Ç–æ–≤
        
        Args:
            topics_data: –î–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–º
            
        Returns:
            str: –ö—Ä–∞—Å–∏–≤–æ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á–µ—Ç
        """
        if not topics_data or 'topics' not in topics_data:
            return "‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"
        
        topics = topics_data['topics']
        if not topics:
            return "‚ùå –¢–µ–º—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã - –ø—Ä–∏–≤–æ–¥–∏–º –∫ —Ä–∞–∑—É–º–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏—è–º
        total_raw_percentage = sum(t.get('percentage', 0) for t in topics)
        
        # –ï—Å–ª–∏ —Å—É–º–º–∞ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –±–æ–ª—å—à–µ 100%, –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        if total_raw_percentage > 100:
            normalization_factor = 100 / total_raw_percentage
            for topic in topics:
                topic['normalized_percentage'] = topic.get('percentage', 0) * normalization_factor
        else:
            for topic in topics:
                topic['normalized_percentage'] = topic.get('percentage', 0)
        
        # –†–∞—Å—á–µ—Ç –ø–æ–∫—Ä—ã—Ç–∏—è –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã
        total_periods = 15  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –∞–Ω–∞–ª–∏–∑ –ø–æ 15 –ø–µ—Ä–∏–æ–¥–∞–º
        
        beautiful_output = []
        beautiful_output.append("üéØ **–ê–ù–ê–õ–ò–ó –í–ê–®–ò–• –ò–ù–¢–ï–†–ï–°–û–í –ò –¢–ï–ú**\n")
        beautiful_output.append("=" * 50 + "\n")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–µ–º—ã –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É –ø—Ä–æ—Ü–µ–Ω—Ç—É
        sorted_topics = sorted(topics, key=lambda x: x.get('normalized_percentage', 0), reverse=True)
        
        for i, topic in enumerate(sorted_topics, 1):
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–µ–º—ã
            topic_name = topic.get('name', f'–¢–µ–º–∞ {i}')
            normalized_percentage = topic.get('normalized_percentage', 0)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–∏–æ–¥–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ–Ω—Ç–∞
            if normalized_percentage >= 20:
                periods_count = max(12, int(total_periods * 0.8))
            elif normalized_percentage >= 15:
                periods_count = max(10, int(total_periods * 0.67))
            elif normalized_percentage >= 10:
                periods_count = max(8, int(total_periods * 0.53))
            elif normalized_percentage >= 5:
                periods_count = max(5, int(total_periods * 0.33))
            else:
                periods_count = max(2, int(total_periods * 0.15))
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–∏–æ–¥–æ–≤ –æ–±—â–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º
            periods_count = min(periods_count, total_periods)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –≤–∞–∂–Ω–æ—Å—Ç–∏
            if periods_count >= 12:
                status = "üî• –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–ï–°"
                coverage_percent = int((periods_count / total_periods) * 100)
            elif periods_count >= 8:
                status = "‚≠ê –í–ê–ñ–ù–ê–Ø –¢–ï–ú–ê"
                coverage_percent = int((periods_count / total_periods) * 100)
            elif periods_count >= 5:
                status = "üí° –ü–ï–†–ò–û–î–ò–ß–ï–°–ö–ê–Ø –¢–ï–ú–ê"
                coverage_percent = int((periods_count / total_periods) * 100)
            else:
                status = "üìù –†–ï–î–ö–ê–Ø –¢–ï–ú–ê"
                coverage_percent = int((periods_count / total_periods) * 100)
            
            # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª—å–Ω—É—é —à–∫–∞–ª—É
            filled_dots = "‚óè" * periods_count
            empty_dots = "‚óã" * (total_periods - periods_count)
            visual_scale = filled_dots + empty_dots
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–º—É
            beautiful_output.append(f"üî• **{topic_name}**")
            beautiful_output.append(f"üìå {status} ({coverage_percent}% –≤—Ä–µ–º–µ–Ω–∏)")
            beautiful_output.append(f"üìä {visual_scale} {periods_count}/{total_periods} –ø–µ—Ä–∏–æ–¥–æ–≤")
            beautiful_output.append(f"‚ö° –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å: {normalized_percentage:.1f}% –ø—Ä–∏ –æ–±—Å—É–∂–¥–µ–Ω–∏–∏")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –µ—Å–ª–∏ –µ—Å—Ç—å
            if topic.get('description'):
                beautiful_output.append(f"üí¨ {topic['description']}")
            
            beautiful_output.append("")  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É —Ç–µ–º–∞–º–∏
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        normalized_total = sum(t.get('normalized_percentage', 0) for t in topics)
        beautiful_output.append("üìà **–û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê**")
        beautiful_output.append(f"üéØ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Ç–µ–º: {len(topics)}")
        beautiful_output.append(f"üìä –ü–æ–∫—Ä—ã—Ç–∏–µ –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤: {normalized_total:.1f}%")
        beautiful_output.append(f"‚è±Ô∏è –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤: {total_periods}")
        
        return "\n".join(beautiful_output)

    def generate_beautiful_client_report(self, topics_data: Dict, commercial_assessment: Dict = None, chat_name: str = "–ö–ª–∏–µ–Ω—Ç") -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫—Ä–∞—Å–∏–≤—ã–π –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–æ–≤–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
        
        Args:
            topics_data: –î–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–º
            commercial_assessment: –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–µ–º
            chat_name: –ò–º—è –∫–ª–∏–µ–Ω—Ç–∞/—á–∞—Ç–∞
            
        Returns:
            str: –ü–æ–ª–Ω—ã–π –∫—Ä–∞—Å–∏–≤—ã–π –æ—Ç—á–µ—Ç –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞
        """
        report_lines = []
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç—á–µ—Ç–∞
        report_lines.append(f"# üéØ –ü–ï–†–°–û–ù–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ò–ù–¢–ï–†–ï–°–û–í")
        report_lines.append(f"## üë§ –ö–ª–∏–µ–Ω—Ç: {chat_name}")
        report_lines.append(f"## üìÖ –î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {datetime.now().strftime('%d.%m.%Y')}")
        report_lines.append("\n" + "=" * 60 + "\n")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫—Ä–∞—Å–∏–≤—ã–π —Ñ–æ—Ä–º–∞—Ç —Ç–µ–º
        beautiful_topics = self.generate_beautiful_topic_format(topics_data)
        report_lines.append(beautiful_topics)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–º–º–µ—Ä—á–µ—Å–∫—É—é –æ—Ü–µ–Ω–∫—É –µ—Å–ª–∏ –µ—Å—Ç—å
        if commercial_assessment and commercial_assessment.get('commercial_assessment'):
            report_lines.append("\n" + "=" * 60 + "\n")
            report_lines.append("üí∞ **–í–û–ó–ú–û–ñ–ù–û–°–¢–ò –ú–û–ù–ï–¢–ò–ó–ê–¶–ò–ò**\n")
            
            commercial_topics = commercial_assessment['commercial_assessment']
            for topic_assessment in commercial_topics:
                topic_name = topic_assessment.get('topic', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Ç–µ–º–∞')
                commercial_score = topic_assessment.get('commercial_score', '–ù–µ –æ—Ü–µ–Ω–µ–Ω–æ')
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º emoji –¥–ª—è –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞
                if '–≤—ã—Å–æ–∫–∏–π' in commercial_score.lower():
                    potential_emoji = "üî•"
                elif '—Å—Ä–µ–¥–Ω–∏–π' in commercial_score.lower():
                    potential_emoji = "‚≠ê"
                else:
                    potential_emoji = "üí°"
                
                report_lines.append(f"{potential_emoji} **{topic_name}**")
                report_lines.append(f"üí∞ –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª: {commercial_score}")
                
                # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–¥—É–∫—Ç—ã –µ—Å–ª–∏ –µ—Å—Ç—å
                if topic_assessment.get('products'):
                    report_lines.append("üõçÔ∏è **–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã:**")
                    for product in topic_assessment['products'][:3]:  # –¢–æ–ø 3 –ø—Ä–æ–¥—É–∫—Ç–∞
                        product_name = product.get('name', '–ü—Ä–æ–¥—É–∫—Ç')
                        revenue_potential = product.get('revenue_potential', '–Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω')
                        report_lines.append(f"   ‚Ä¢ {product_name} (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª: {revenue_potential})")
                
                report_lines.append("")  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        report_lines.append("\n" + "=" * 60 + "\n")
        report_lines.append("üéØ **–ü–ï–†–°–û–ù–ê–õ–¨–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò**\n")
        
        if topics_data and topics_data.get('topics'):
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            topics = topics_data['topics']
            total_raw_percentage = sum(t.get('percentage', 0) for t in topics)
            
            if total_raw_percentage > 100:
                normalization_factor = 100 / total_raw_percentage
                for topic in topics:
                    topic['normalized_percentage'] = topic.get('percentage', 0) * normalization_factor
            else:
                for topic in topics:
                    topic['normalized_percentage'] = topic.get('percentage', 0)
            
            top_topics = sorted(topics, key=lambda x: x.get('normalized_percentage', 0), reverse=True)[:3]
            
            report_lines.append("–ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –≤–∞—à–∏—Ö –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤ –º—ã —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º:")
            report_lines.append("")
            
            for i, topic in enumerate(top_topics, 1):
                topic_name = topic.get('name', f'–¢–µ–º–∞ {i}')
                percentage = topic.get('normalized_percentage', 0)
                report_lines.append(f"**{i}. –†–∞–∑–≤–∏–≤–∞–π—Ç–µ –∏–Ω—Ç–µ—Ä–µ—Å –∫ —Ç–µ–º–µ \"{topic_name}\"**")
                report_lines.append(f"   ‚Ä¢ –≠—Ç–∞ —Ç–µ–º–∞ –∑–∞–Ω–∏–º–∞–µ—Ç {percentage:.1f}% –≤–∞—à–∏—Ö –æ–±—Å—É–∂–¥–µ–Ω–∏–π")
                report_lines.append(f"   ‚Ä¢ –í—ã—Å–æ–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è —É–≥–ª—É–±–ª–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π")
                report_lines.append("")
        
        # –ü–æ–¥–ø–∏—Å—å
        report_lines.append("---")
        report_lines.append("üìä *–û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —Å–∏—Å—Ç–µ–º–æ–π –∞–Ω–∞–ª–∏–∑–∞ TelegramSoul*")
        report_lines.append(f"‚è∞ *–í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {datetime.now().strftime('%d.%m.%Y %H:%M')}*")
        
        return "\n".join(report_lines)

# –ü—Ä–æ–º–ø—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–º
# –ü—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–º–∞—Ç–∏–∫–∏
TOPIC_ANALYSIS_PROMPT = """
–ö–∞–∫ –æ–ø—ã—Ç–Ω—ã–π –±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏—Ç–∏–∫ –∏ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏, –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ Telegram-—á–∞—Ç–∞. 
–í—ã–≤–µ–¥–∏—Ç–µ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –æ–±—Å—É–∂–¥–µ–Ω–∏—è, –∏–Ω—Ç–µ—Ä–µ—Å—ã —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –∏ —Å–∫—Ä—ã—Ç—ã–µ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏.

–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:
1. 5-7 –û—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ–º, –æ –∫–æ—Ç–æ—Ä—ã—Ö –≥–æ–≤–æ—Ä—è—Ç —É—á–∞—Å—Ç–Ω–∏–∫–∏ (–æ—Ç –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ —É–ø–æ–º–∏–Ω–∞–µ–º—ã—Ö –∫ –Ω–∞–∏–º–µ–Ω–µ–µ —á–∞—Å—Ç–æ —É–ø–æ–º–∏–Ω–∞–µ–º—ã–º)
2. –î–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã —É–∫–∞–∂–∏—Ç–µ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –∏ –ø—Ä–æ—Ü–µ–Ω—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç –æ–±—â–µ–≥–æ —á–∏—Å–ª–∞
3. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –æ–∫—Ä–∞—Å–∫—É –æ–±—Å—É–∂–¥–µ–Ω–∏—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã (–ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è/–Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è/–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è)
4. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–µ–º—ã –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ–±—Å—É–∂–¥–µ–Ω–∏—è

–°–û–û–ë–©–ï–ù–ò–Ø:
{messages}

–í–µ—Ä–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:
{{
    "topics": [
        {{
            "name": "–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã",
            "keywords": ["–∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ 1", "–∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ 2", ...],
            "percentage": XX.X,
            "sentiment": "positive/negative/neutral",
            "description": "–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–µ–º—ã –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ–±—Å—É–∂–¥–µ–Ω–∏—è"
        }},
        ...
    ]
}}
"""

# –ü—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏
MONETIZATION_ANALYSIS_PROMPT = """
–ö–∞–∫ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏ –∏ –±–∏–∑–Ω–µ—Å-–º–æ–¥–µ–ª–∏, –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —á–∞—Ç–∞ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã.
–ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–∏—Ö —Ç–µ–º –∏ –∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫:
{topics_json}

–†–∞–∑—Ä–∞–±–æ—Ç–∞–π—Ç–µ –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã:
1. 3-5 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤/—É—Å–ª—É–≥, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å
2. –ù–∞–∏–±–æ–ª—å—à—É—é –ø–æ–¥—Ö–æ–¥—è—â—É—é –º–æ–¥–µ–ª—å –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏ (–ø–æ–¥–ø–∏—Å–∫–∞/—Ä–∞–∑–æ–≤–∞—è –æ–ø–ª–∞—Ç–∞/freemium –∏ —Ç.–¥.)
3. –û—Ü–µ–Ω–∫—É –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ –¥–æ—Ö–æ–¥–∞ (–Ω–∏–∑–∫–∏–π/—Å—Ä–µ–¥–Ω–∏–π/–≤—ã—Å–æ–∫–∏–π)
4. –°–ª–æ–∂–Ω–æ—Å—Ç—å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ (–Ω–∏–∑–∫–∞—è/—Å—Ä–µ–¥–Ω—è—è/–≤—ã—Å–æ–∫–∞—è)
5. –í—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è –∑–∞–ø—É—Å–∫–∞ (–∫–æ—Ä–æ—Ç–∫–∏–π/—Å—Ä–µ–¥–Ω–∏–π/–¥–ª–∏–Ω–Ω—ã–π)

–í–µ—Ä–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:
{{
    "monetization_strategies": [
        {{
            "topic": "–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã",
            "products": [
                {{
                    "name": "–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞/—É—Å–ª—É–≥–∏",
                    "description": "–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞/—É—Å–ª—É–≥–∏",
                    "model": "–ú–æ–¥–µ–ª—å –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏",
                    "revenue_potential": "–Ω–∏–∑–∫–∏–π/—Å—Ä–µ–¥–Ω–∏–π/–≤—ã—Å–æ–∫–∏–π",
                    "implementation_complexity": "–Ω–∏–∑–∫–∞—è/—Å—Ä–µ–¥–Ω—è—è/–≤—ã—Å–æ–∫–∞—è",
                    "timeframe": "–∫–æ—Ä–æ—Ç–∫–∏–π/—Å—Ä–µ–¥–Ω–∏–π/–¥–ª–∏–Ω–Ω—ã–π"
                }},
                ...
            ]
        }},
        ...
    ]
}}
"""

# –ü—Ä–æ–º–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–∏–∑–Ω–µ—Å-–ø–ª–∞–Ω–∞
BUSINESS_PLAN_PROMPT = """
–ö–∞–∫ –æ–ø—ã—Ç–Ω—ã–π –±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏—Ç–∏–∫ –∏ –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏, –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —á–∞—Ç–∞ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç–µ –±–∏–∑–Ω–µ—Å-–ø–ª–∞–Ω –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã.
–ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–∏—Ö —Ç–µ–º –∏ –∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫:
{topics_json}

–†–∞–∑—Ä–∞–±–æ—Ç–∞–π—Ç–µ –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã:
1. 3-5 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤/—É—Å–ª—É–≥, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å
2. –ù–∞–∏–±–æ–ª—å—à—É—é –ø–æ–¥—Ö–æ–¥—è—â—É—é –º–æ–¥–µ–ª—å –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏ (–ø–æ–¥–ø–∏—Å–∫–∞/—Ä–∞–∑–æ–≤–∞—è –æ–ø–ª–∞—Ç–∞/freemium –∏ —Ç.–¥.)
3. –û—Ü–µ–Ω–∫—É –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ –¥–æ—Ö–æ–¥–∞ (–Ω–∏–∑–∫–∏–π/—Å—Ä–µ–¥–Ω–∏–π/–≤—ã—Å–æ–∫–∏–π)
4. –°–ª–æ–∂–Ω–æ—Å—Ç—å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ (–Ω–∏–∑–∫–∞—è/—Å—Ä–µ–¥–Ω—è—è/–≤—ã—Å–æ–∫–∞—è)
5. –í—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è –∑–∞–ø—É—Å–∫–∞ (–∫–æ—Ä–æ—Ç–∫–∏–π/—Å—Ä–µ–¥–Ω–∏–π/–¥–ª–∏–Ω–Ω—ã–π)

–í–µ—Ä–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:
{{
    "business_plan": {{
        "executive_summary": {{
            "concept": "",
            "target_audience": "",
            "value_proposition": ""
        }},
        "market_analysis": {{
            "market_size": "",
            "trends": [],
            "competitors": []
        }},
        "product_description": {{
            "features": [],
            "usp": ""
        }},
        "business_model": {{
            "pricing": "",
            "sales_channels": []
        }},
        "marketing_strategy": {{
            "acquisition_channels": [],
            "retention_methods": []
        }},
        "operational_plan": {{
            "resources": [],
            "team": [],
            "timeline": {{}}
        }},
        "financial_forecast": {{
            "initial_investment": "",
            "breakeven": "",
            "roi": ""
        }},
        "risks": [
            {{
                "description": "",
                "mitigation": ""
            }}
        ]
    }}
}}
"""
